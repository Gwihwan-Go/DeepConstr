constraints:
  input:
    default: null
    dtype: float16,float32,float64,uint8,complex64,complex128,int8,int16,int32,int64,bool
    init: false
    required: true
  out:
    default: null
    dtype: float16,float32,float64,uint8,complex64,complex128,int8,int16,int32,int64,bool
    init: false
    required: false
package: torch
pass_rate: 0.95
rules:
- cot: The error occurs because of an attempt to resize a non-resizable storage. The
    'input' tensor has a shape of [9,8] and the 'out' tensor has a shape of [1,3].
    The error implies that there is an attempt to resize the 'out' tensor to match
    the 'input' tensor, which is incorrect because tensor storages are not resizable.
    Therefore, the constraint should be that the dimensions of 'out' must match the
    dimensions of 'input'.
  target: Trying to resize storage that is not resizable
  txt: len(input.shape) == len(out.shape) and all(input.shape[i] == out.shape[i] for
    i in range(len(input.shape)))

title: torch.square
