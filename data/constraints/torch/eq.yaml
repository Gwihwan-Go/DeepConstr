alias: torch.eq
constraints:
  input:
    default: null
    dtype: float16,float32,float64,uint8,complex64,complex128,int8,int16,int32,int64,bool
    init: false
    required: true
  other:
    default: null
    dtype: float16,float32,float64,uint8,complex64,complex128,int8,int16,int32,int64,bool,float32
    init: false
    required: true
  out:
    default: null
    dtype: float16,float32,float64,uint8,complex64,complex128,int8,int16,int32,int64,bool
    init: false
    required: false
infered_history: []
infered_times: 16
package: torch
pass_rate: 1.0
rules:
- cot: 'Error is triggered because we are trying to resize a storage that is not resizable.
    From the given values, it seems that ''out'' tensor has different shape from ''input''
    and ''other'' tensors. In this case, ''out'' tensor shape should be matched with
    the ''input'' and ''other'' tensor shapes for the operation. Therefore, left :
    out.shape, out.rank op : == right : input.shape, input.rank or other.shape, other.rank.'
  target: Trying to resize storage that is not resizable
  txt: (len(input.shape) == 2) and (out.rank==input.rank and all(out.shape[i]==input.shape[i]
    for i in range(out.rank)) and out.rank==other.rank and all(out.shape[i]==other.shape[i]
    for i in range(out.rank)))
time_cost: 4417.551847934723
title: torch.eq
tokens_used: 9368
trained: true
