alias: torch.tanh
constraints:
  input:
    default: null
    dtype: float16,float32,float64,uint8,complex64,complex128,int8,int16,int32,int64,bool
    init: false
    required: true
  out:
    default: null
    dtype: float16,float32,float64,uint8,complex64,complex128,int8,int16,int32,int64,bool
    init: false
    required: false
infered_history: []
infered_times: 26
package: torch
pass_rate: 1.0
rules:
- cot: 'The error is because we are trying to resize a storage that is not resizable.
    It seems we have two tensors here, ''input'' and ''out''. Both tensors have different
    shapes. The ''input'' tensor has a shape of [9, 8, 8, 8, 8] and the ''out'' tensor
    has a shape of [3, 2, 8, 1, 6, 9, 8]. We need to ensure that the ''input'' and
    ''out'' tensors have the same shape or that ''out'' tensor is resizable. Therefore,
    Left: input.shape == out.shape or out, Op: ==, and Right: True.'
  target: Trying to resize storage that is not resizable
  txt: (out.rank == input.rank and all(out.shape[i] == input.shape[i] for i in range(out.rank))) or (input.shape == out.shape)
- cot: 'The error is triggered because the output tensor type is not compatible with
    the input tensor type. The input tensor is of type ComplexDouble and the output
    tensor is of type Float. Hence, left : input.dtype, op : == , right : ''ComplexDouble''
    and left : out.dtype, op : == , right : ''Float''. The operation should ensure
    that the input and output tensor types are compatible. Therefore, the constraints
    are:'
  target: result type ComplexDouble can't be cast to the desired output type Float
  txt: (input.dtype=='float32') and (out.dtype == 'Float')
time_cost: 1439.7572326660156
title: torch.tanh
tokens_used: 13624
trained: true
