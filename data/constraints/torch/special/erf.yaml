alias: torch.special.erf
constraints:
  input:
    default: null
    dtype: float16,float32,float64,uint8,complex64,complex128,int8,int16,int32,int64,bool
    init: false
    required: true
  out:
    default: null
    dtype: float16,float32,float64,uint8,complex64,complex128,int8,int16,int32,int64,bool
    init: false
    required: false
infered_history: []
infered_times: 30
package: torch
pass_rate: 0.85
rules:
- cot: 'The error is triggered because result type ComplexDouble cannot be cast to
    the Float. Let''s see what the args were. The dtype of ''input'' is complex128
    and the dtype of ''out'' is float32. These two types are incompatible. Therefore,
    the dtypes of the input and output should be consistent. Left : type(input), op
    : ==, comparator : type(out)'
  target: result type Float can't be cast to the desired output type Long
  txt: type(input)==type(out)
- cot: 'The error occurs because the ''out'' tensor is trying to be resized to a size
    that is not allowed. The size of the ''out'' tensor should be equal to the size
    of the ''input'' tensor to avoid this error. Therefore, the constraint should
    be that the dimensions of the ''out'' tensor must be equal to the dimensions of
    the ''input'' tensor. This can be expressed as follows:'
  target: Trying to resize storage that is not resizable
  txt: out.shape == input.shape
- cot: 'The error is due to the implementation of "erf_vml_cpu" not being available
    for ''ComplexDouble'' type. From the given values, it seems that ''input'' and
    ''out'' tensors are of complex128 type. Therefore, the type of ''input'' and ''out''
    should not be complex128. So, the Left : type(input) or type(out) should be corrected.
    Op : !=, and Right : complex128.'
  target: '"erf_vml_cpu" not implemented for ''ComplexDouble'''
  txt: type(out) != "complex128"
- cot: 'The error is due to the use of a complex data type, which is not implemented
    for the "erf_vml_cpu". The tensors ''input'' and ''out'' are both provided as
    complex64, which is not compatible. Let''s see the data types. It seems input.dtype
    and out.dtype are complex64, and is the problem. Therefore, the data types of
    ''input'' and ''out'' should be corrected. Left : input.dtype and out.dtype. It
    says that complex type is not implemented for ''erf_vml_cpu'', so Op : !=, and
    Right : ''complex64''.'
  target: '"erf_vml_cpu" not implemented for ''ComplexFloat'''
  txt: out.dtype != 'complex64'
time_cost: 3026.546792984009
title: torch.special.erf
tokens_used: 18608
trained: true
