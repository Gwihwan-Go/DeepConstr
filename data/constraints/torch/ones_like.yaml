constraints:
  input:
    default: null
    dtype: float16,float32,float64,uint8,complex64,complex128,int8,int16,int32,int64,bool
    init: false
    required: true
  requires_grad:
    default: false
    dtype: bool
    init: false
    required: false
infered_history: []
infered_times: 6
package: torch
pass_rate: 1.0
rules:
- cot: 'The error is caused because the tensor is of integer type (int16), but requires_grad
    is set to True. Gradients can only be computed for floating point and complex
    types. The dtype of the input tensor should be either floating point or complex
    when requires_grad is set to True. So, input.dtype should be in [float16, float32,
    float64, complex64, complex128], Op : in, and Right : [float16, float32, float64,
    complex64, complex128]'
  target: Only Tensors of floating point and complex dtype can require gradients
  txt: (requires_grad==False) or (input.dtype in ['float16', 'float32', 'float64',
    'complex64', 'complex128'])
time_cost: 378.33193612098694
title: torch.ones_like
tokens_used: 4745
trained: true
