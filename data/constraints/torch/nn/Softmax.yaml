constraints:
  dim:
    default: null
    dtype: int
    init: true
    required: false
  input:
    default: null
    dtype: float16,float32,float64,uint8,complex64,complex128,int8,int16,int32,int64,bool
    init: false
    required: true
infered_history: []
infered_times: 10
package: torch
pass_rate: 0.97
rules:
- cot: 'The error is related to the softmax_lastdim_kernel_impl which is not implemented
    for ''ComplexDouble''. Let''s see what the args were. The ''input'' has a type
    of ''ComplexDouble'' which is causing the problem. Therefore, the type of the
    ''input'' should not be ''ComplexDouble''. Hence, Left : type(''input''), Op :
    !=, Right : ''ComplexDouble''.'
  target: '"softmax_lastdim_kernel_impl" not implemented for ''ComplexDouble'''
  txt: type('input') != 'ComplexDouble'
- cot: "The error is due to incorrect data type for the 'input' attribute in the softmax_lastdim_kernel_impl\
    \ function. The function doesn't support 'Int' data type. The 'input' given is\
    \ a tensor with dtype int32 which is not supported. Therefore, the dtype of 'input'\
    \ should not be 'Int' or any integer type. The dtype of 'input' can be float32,\
    \ float64, etc. \n\nHere is the constraint:"
  target: '"softmax_lastdim_kernel_impl" not implemented for ''Int'''
  txt: input.dtype not in ['Int']
- cot: The error is due to the 'dim' value being out of range. Let's examine the given
    args. The 'dim' value is 5 but the valid range is from -1 to 0 inclusive. Therefore,
    the constraint is -1 <= dim <= 0. Also, the 'input' is a tensor of rank 0 since
    its shape is empty. The 'dim' value should be less than the rank of the 'input'
    tensor. Therefore, 'dim' < len(input.shape) is another constraint.
  target: Dimension out of range (expected to be in range of [-1, 0], but got 5)
  txt: (dim >= -1 and dim <= 0) or (dim < len(input.shape))
time_cost: 268.3495578765869
title: torch.nn.Softmax
tokens_used: 4965
