constraints:
  alpha:
    default: 1.0
    dtype: float
    init: false
    required: false
  inplace:
    default: false
    dtype: bool
    init: false
    required: false
  input:
    default: null
    dtype: float16,float32,float64,uint8,complex64,complex128,int8,int16,int32,int64,bool
    init: false
    required: true
infered_history: []
infered_times: 7
package: torch
pass_rate: 1.0
rules:
- cot: 'Error is triggered because elu_cpu is not implemented for ''Char''. Let''s
    see what the args were. It seems input tensor data type ''Char'' or ''int8'' is
    the problem. The data type of input tensor should be corrected, which can be accessed
    by input.dtype. Therefore, Left : input.dtype. It says that it''s not implemented
    for ''Char'', so Op : !=, and Right : ''Char''. It might be useful to ensure the
    data type is one of the commonly used float types. So, Op : ==, and Right : ''float32''
    or ''float64''.'
  target: '"elu_cpu" not implemented for ''Char'''
  txt: input.dtype == 'float64'
time_cost: 269.4516398906708
title: torch.nn.functional.elu
tokens_used: 4244
trained: true
