constraints:
  input:
    default: null
    dtype: float16,float32,float64,uint8,complex64,complex128,int8,int16,int32,int64,bool
    init: false
    required: true
  output_size:
    default: null
    dtype: int
    init: false
    required: true
  return_indices:
    default: false
    dtype: bool
    init: false
    required: false
infered_history: []
infered_times: 11
package: torch
pass_rate: 1.0
rules:
- cot: 'The error is due to an input tensor having zero size for non-batch dimensions.
    The input tensor is expected to have non-zero size for non-batch dimension, but
    it has sizes [0, 0, 0] with dimension 1 being empty. So, the left : input[i],
    i in (1,len(input.shape)). op : !=, right : 0.'
  target: 'adaptive_max_pool1d(): Expected input to have non-zero size for non-batch
    dimensions, but input has sizes [0, 0, 0] with dimension 1 being empty'
  txt: output_size >= 0
- cot: 'Error is triggered because of 5-dimensional tensor. it expects to have 2 or
    3 dimensions. Let''s see what the args were. It seems input tensor has 5 dimensions,
    and is the problem. so the number of dimensions of input tensor should be corrected,
    which is input.ndims(). Therefore, Left : input.ndims(). It says that expected
    2 to 3, so Op : ==, and Right : 2 or 3. Also, It implies that dimension cannot
    be 5, so Op : !=, and Right : 5.'
  target: 'Expected 2 to 3 dimensions, but got 5-dimensional tensor for argument #1
    ''self'' (while checking arguments for adaptive_max_pool1d)'
  txt: (input.ndims() == 2) or (input.ndims() == 3)
- cot: 'The error is caused by the ''adaptive_max_pool2d'' function which is not implemented
    for ''Int'' datatype. What the args were? The input tensor is of dtype ''int32''
    and the function ''adaptive_max_pool2d'' does not support this datatype. Therefore,
    the datatype of input tensor should be changed to one which is supported, such
    as ''float''. So, Left : input.dtype, Op : ==, Right : float. Additionally, the
    ''output_size'' is set to 8, but we don''t have information on any constraints
    regarding this. The ''return_indices'' is set to True, but again there''s no information
    on whether this could cause an issue.'
  target: '"adaptive_max_pool2d" not implemented for ''Int'''
  txt: (input.dtype == float)
time_cost: 410.1707043647766
title: torch.nn.functional.adaptive_max_pool1d_with_indices
tokens_used: 6389
trained: true
