constraints:
  input:
    default: 'null'
    dtype: float16,float32,float64,uint8,complex64,complex128,int8,int16,int32,int64,bool
    init: false
    required: true
  out:
    default: 'null'
    dtype: float16,float32,float64,uint8,complex64,complex128,int8,int16,int32,int64,bool
    init: false
    required: false
infered_history: []
infered_times: 8
package: torch
pass_rate: 0.93
rules:
- cot: 'The error is triggered because the ''out'' tensor shape does not match with
    the ''input'' tensor shape. In this case, the ''input'' tensor has a shape of
    [6, 8, 6, 6, 1, 3, 4, 1, 2, 2] and ''out'' tensor has a shape of [8, 2, 6]. This
    means that the operation is trying to resize ''out'' tensor to match with the
    ''input'' tensor shape, which is not possible as ''out'' tensor is not resizable.


    To prevent this error, we can create a logical relationship constraint that ensures
    ''out'' tensor shape is always equal to ''input'' tensor shape. This can be done
    by setting the ''out'' tensor shape to be equal to the ''input'' tensor shape
    before the operation starts.


    The constraint can be defined as follows:'
  target: Trying to resize storage that is not resizable
  txt: out.shape == input.shape
time_cost: 377.9870047569275
title: torch.angle
tokens_used: 4003
trained: true
