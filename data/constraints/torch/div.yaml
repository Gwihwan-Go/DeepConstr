alias: torch.div
constraints:
  input:
    default: 'null'
    dtype: float16,float32,float64,uint8,complex64,complex128,int8,int16,int32,int64,bool
    init: false
    required: true
  other:
    default: 'null'
    dtype: float16,float32,float64,uint8,complex64,complex128,int8,int16,int32,int64,bool,int
    init: false
    required: true
  out:
    default: 'null'
    dtype: float16,float32,float64,uint8,complex64,complex128,int8,int16,int32,int64,bool
    init: false
    required: false
  rounding_mode:
    default: 'null'
    dtype: Literal["trunc", "floor"]
    init: false
    required: false
package: torch
pass_rate: 0.88
rules:
- cot: "The error implies that the storage dimension for certain Tensors is trying\
    \ to be resized which is not allowed. Looking at the values, 'input', 'other'\
    \ and 'out', the dimensions mismatch. For the operation, it is assumed that the\
    \ dimensions of 'input' and 'other' tensors should match, and the output tensor\
    \ 'out' might be of different dimensions. Therefore, to prevent this error from\
    \ happening again, we need to ensure that the dimensions of the 'input' and 'other'\
    \ tensors match. The constraints extraction steps are as follows,\n\nLeft : dimensions\
    \ of 'input', \nOp : '==', \nRight : dimensions of 'other'."
  target: Trying to resize storage that is not resizable
  txt: (all(out.shape[i] == other.shape[i] for i in range(other.rank))) and ((out.rank==input.rank
    and out.rank==other.rank and all(out.shape[i]==input.shape[i] for i in range(out.rank))
    and all(out.shape[i]==other.shape[i] for i in range(out.rank))))
- cot: 'The error is caused because the result type is ''ComplexFloat'' and it cannot
    be cast to the desired output type ''Float''. From the given values, ''input''
    and ''other'' are ''complex64'' type and ''out'' is ''float32'' type. The ''rounding_mode''
    is ''floor''. Therefore, Left : input.dtype and other.dtype, Op : ==, Right :
    ComplexFloat, which means the types of ''input'' and ''other'' should be ''ComplexFloat''.
    And Left : out.dtype, Op : ==, Right : Float, which means the type of ''out''
    should be ''Float''.'
  target: result type ComplexDouble can't be cast to the desired output type Float
  txt: out.dtype==Float
- cot: "Error is triggered because the size of tensors at non-singleton dimension\
    \ 5 doesn't match. In the given values, 'input' tensor and 'other' tensor's dimension\
    \ 5 sizes are 4 and 8 respectively, which is causing the error. \n\nFor non-singleton\
    \ dimensions, the size of the tensors should match or one of them should be 1\
    \ to perform broadcasting. \n\nTherefore, we can revise the constraints as:"
  target: The size of tensor a (4) must match the size of tensor b (8) at non-singleton
    dimension 5
  txt: (input.shape[5] == other.shape[5]) and (all(input.shape[i] == other.shape[i]
    or input.shape[i] == 1 or other.shape[i] == 1 for i in range(-1, -min(len(input.shape),
    len(other.shape))-1, -1)))
title: torch.div
trained: true
