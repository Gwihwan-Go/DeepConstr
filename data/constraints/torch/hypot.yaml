constraints:
  input:
    default: 'null'
    dtype: float16,float32,float64,uint8,complex64,complex128,int8,int16,int32,int64,bool
    init: false
    required: true
  other:
    default: 'null'
    dtype: float16,float32,float64,uint8,complex64,complex128,int8,int16,int32,int64,bool
    init: false
    required: true
  out:
    default: 'null'
    dtype: float16,float32,float64,uint8,complex64,complex128,int8,int16,int32,int64,bool
    init: false
    required: false
infered_history: []
infered_times: 34
package: torch
pass_rate: 0.9
rules:
- cot: 'The error is triggered because the sizes of tensors ''input'' and ''other''
    at non-singleton dimension 4 don''t match. Here, ''input'' tensor has size 8 and
    ''other'' tensor has size 9 at the mentioned dimension. Broadcasting in tensor
    operations requires that trailing dimensions of the tensors should either be 1
    or the same. We start from the last dimension because broadcasting aligns dimensions
    from the end. Therefore, the constraints can be revised to ensure that the sizes
    of the tensors match or are equal to 1 at non-singleton dimension 4. Here is how
    we can generate constraints:'
  target: The size of tensor a (8) must match the size of tensor b (9) at non-singleton
    dimension 4
  txt: all(input.shape[i] == other.shape[i] or input.shape[i] == 1 or other.shape[i]
    == 1 for i in range(-1, -min(len(input.shape), len(other.shape))-1, -1))
- cot: 'Error is triggered because of trying to resize storage. Let''s see what the
    args were. I guess the storage indicates ''out'' tensor. So, it means that ''out''
    tensor shape should be matched with the operation results. In this operation,
    the result shape is input.shape. Therefore, left : out.shape, out.rank, op : ==,
    right : input.shape, input.rank.'
  target: Trying to resize storage that is not resizable
  txt: (other.rank==input.rank and all(other.shape[i]==input.shape[i] for i in range(other.rank)))
    and ((len(other) != 0) and (out.rank==input.rank and all(out.shape[i]==input.shape[i]
    for i in range(out.rank))))
- cot: 'The error is caused by a datatype mismatch. What the args were? The ''input''
    tensor is of datatype ''complex128'', while the ''out'' tensor is expected to
    be of datatype ''float32''. But ''complex128'' can''t be cast to ''float32''.
    Therefore, left : input.dtype, op : ==, right : other.dtype, float32 and also
    left : input.dtype, op : ==, right : out.dtype, float32. This means, the data
    type of all the tensors involved should be the same, here ''float32''.'
  target: result type ComplexDouble can't be cast to the desired output type Float
  txt: out.dtype == input.dtype
time_cost: 10836.954749584198
title: torch.hypot
tokens_used: 17797
trained: true
