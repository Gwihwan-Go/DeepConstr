constraints:
  A:
    default: 'null'
    dtype: float16,float32,float64,uint8,complex64,complex128,int8,int16,int32,int64,bool
    init: false
    required: true
  out:
    default: 'null'
    dtype: float16,float32,float64,uint8,complex64,complex128,int8,int16,int32,int64,bool
    init: false
    required: false
infered_history: []
infered_times: 36
package: torch
pass_rate: 0.98
rules:
- cot: 'The error is triggered because we are trying to resize storage that is not
    resizable. Let''s see what the args were. From the given values, it seems that
    ''out'' tensor shape does not match with ''A'' tensor shape. Therefore, the shape
    of ''out'' tensor should be corrected to match with ''A''. Left : out.shape, out.rank.
    Op : ==. Right : A.shape, A.rank.'
  target: Trying to resize storage that is not resizable
  txt: out.rank==A.rank and all(out.shape[i]==A.shape[i] for i in range(out.rank))
- cot: 'The error is raised because the linalg.svd function requires an input tensor
    with at least 2 dimensions, but the tensor ''A'' here has only 1 dimension. Let''s
    see what the args were. It seems ''A'' tensor has 1 dimension, and is the problem.
    Therefore, Left : A.ndims(). It says that should be at least 2, so Op : >=, and
    Right : 2.'
  target: 'linalg.svd: The input tensor A must have at least 2 dimensions.'
  txt: A.ndims() >= 2
- cot: 'The error is related to the data type of the input tensor for the svd operation.
    The svd operation requires a floating point or complex tensor, but the input tensor
    is of type int8. Therefore, the constraint is that the input tensor type should
    be a floating point or complex tensor. Let''s see what the args were. For the
    ''A'' tensor, it''s currently of dtype int8, so Left : A.dtype, but it should
    be a floating point or complex type, so Op : == and Right : float or complex type.'
  target: 'linalg.svd: Expected a floating point or complex tensor as input. Got Char'
  txt: A.dtype == float or A.dtype == complex
- cot: 'The error is triggered because the ''out'' tensor has a dtype of complex64,
    but it was expected to be float. Let''s analyze the values. It seems ''out'' tensor
    has dtype complex64, which is the issue. Therefore, the dtype of ''out'' should
    be corrected, which is ''A''.dtype. Thus, Left : ''out''.dtype. It says that should
    be equal to the dtype of ''A'', so Op : ==, and Right : ''A''.dtype.'
  target: Expected out tensor to have dtype float, but got c10::complex<float> instead
  txt: '''out''.dtype == ''A''.dtype'
- cot: 'The error is triggered because the ''out'' tensor has a complex dtype, while
    it is expected to be of type double. Let''s check the dtype of ''out''. Left:
    out.dtype. It is expected to be double, so Op: ==, and Right: double. Moreover,
    it cannot be complex, so Op: !=, and Right: complex.'
  target: Expected out tensor to have dtype double, but got c10::complex<double> instead
  txt: out.dtype != complex
time_cost: 1223.6630909442902
title: torch._C._linalg.linalg_svdvals
tokens_used: 20257
trained: true
