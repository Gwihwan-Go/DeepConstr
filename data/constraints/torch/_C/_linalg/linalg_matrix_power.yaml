constraints:
  input:
    default: null
    dtype: float16,float32,float64,uint8,complex64,complex128,int8,int16,int32,int64,bool
    init: false
    required: true
  n:
    default: null
    dtype: int
    init: false
    required: true
  out:
    default: null
    dtype: float16,float32,float64,uint8,complex64,complex128,int8,int16,int32,int64,bool
    init: false
    required: false
infered_history: []
infered_times: 23
package: torch
pass_rate: 0.9
rules:
- cot: 'The error is caused because the output of a matrix power operation is expected
    to be Float dtype but got Int dtype. What''s the args were? The input tensor has
    a float32 dtype and the result tensor has an int32 dtype. Therefore, the dtype
    of the result tensor should be equal to the dtype of the input tensor. Left :
    out.dtype, Op : ==, and Right : input.dtype.'
  target: 'matrix_power: Expected result to be safely castable from Float dtype, but
    got result with dtype Int'
  txt: out.dtype == input.dtype
- cot: The error is caused because the 'input' matrix is not a square matrix. For
    a matrix to be square, the number of rows should be equal to the number of columns.
    Therefore, the constraint should be that the dimensions of the 'input' matrix
    are equal.
  target: 'linalg.matrix_power: A must be batches of square matrices, but they are
    8 by 6 matrices'
  txt: (input.shape[-2] == input.shape[-1]) and (input.shape[0] == input.shape[1])
- cot: 'Error is triggered because the input tensor A doesn''t have at least 2 dimensions.
    Let''s see what the args were. ''input'' is a tensor which only has 1 dimension.
    Therefore, Left : len(input.shape), should be corrected. It states that it should
    have at least 2 dimensions, so Op : >=, and Right : 2.'
  target: 'linalg.matrix_power: The input tensor A must have at least 2 dimensions.'
  txt: len(input.shape)>=2
- cot: "The error is triggered because of an attempt to resize an unresizable tensor.\
    \ Here, the 'out' tensor has a size of [4] while the input tensor is of size [6,6].\
    \ So, the 'out' tensor size is not matching with the input tensor size. The 'out'\
    \ tensor should have the same size as the input tensor for the operation to be\
    \ successful. Therefore, the constraints should be 'out.rank == input.rank' and\
    \ 'out.shape[i] == input.shape[i] for all i in range(out.rank)'. \n\nIt means,\
    \ the constraints should be:"
  target: Trying to resize storage that is not resizable
  txt: (len(out) == n) and (out.rank == input.rank and all(out.shape[i] == input.shape[i]
    for i in range(out.rank)))
time_cost: 1557.314773797989
title: torch._C._linalg.linalg_matrix_power
tokens_used: 10773
trained: true
