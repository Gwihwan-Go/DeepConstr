constraints:
  n:
    default: null
    dtype: float16,float32,float64,uint8,complex64,complex128,int8,int16,int32,int64,bool
    init: false
    required: true
  x:
    default: null
    dtype: float16,float32,float64,uint8,complex64,complex128,int8,int16,int32,int64,bool
    init: false
    required: true
infered_history: []
infered_times: 10
package: torch
pass_rate: 0.93
rules:
- cot: "The error occurs because the tensors 'x' and 'n' do not have matching sizes\
    \ at non-singleton dimension 5. The size of tensor 'x' at dimension 5 is 3, and\
    \ the size of tensor 'n' at the same dimension is 8. \n\nA possible constraint\
    \ to prevent this error is to ensure that for all non-singleton dimensions, the\
    \ sizes of the tensors are either equal or one of them is 1 (to allow broadcasting).\
    \ \n\nFor the given tensors 'x' and 'n', we first need to ensure that their dimensions\
    \ are compatible. The tensor 'x' has 7 dimensions and 'n' has 2 dimensions. However,\
    \ since broadcasting aligns tensors starting from the last dimension, we can ignore\
    \ the leading dimensions of the larger tensor if the sizes of trailing dimensions\
    \ of both tensors are compatible. \n\nTherefore, the constraint can be:"
  target: The size of tensor a (4) must match the size of tensor b (8) at non-singleton
    dimension 2
  txt: all(x.shape[i] == n.shape[i] or x.shape[i] == 1 or n.shape[i] == 1 for i in
    range(-1, -min(len(x.shape), len(n.shape))-1, -1))
- cot: 'The error is due to the function "chebyshev_polynomial_u_cpu" not being implemented
    for ''ComplexFloat''. Checking the args, the tensor ''n'' is of type ''complex64'',
    which is likely the cause of the issue. Therefore, Left : type(n). Since it''s
    not implemented for ''ComplexFloat'', so Op: !=, and Right: ComplexFloat. Also,
    to avoid any other unimplemented types, it would be safer to ensure ''n'' is of
    type ''float64'', so Op: ==, and Right: float64.'
  target: '"chebyshev_polynomial_u_cpu" not implemented for ''ComplexFloat'''
  txt: type(n) == float64
time_cost: 35174.214223861694
title: torch._C._special.special_chebyshev_polynomial_u
tokens_used: 6653
trained: true
