constraints:
  input:
    default: null
    dtype: float16,float32,float64,uint8,complex64,complex128,int8,int16,int32,int64,bool
    init: false
    required: true
  out:
    default: null
    dtype: float16,float32,float64,uint8,complex64,complex128,int8,int16,int32,int64,bool
    init: false
    required: false
infered_history: []
infered_times: 22
package: torch
pass_rate: 0.78
rules:
- cot: 'The error comes from trying to cast a float tensor to an integer tensor. You
    cannot directly cast a float to an int. So, the ''input'' tensor is of type float32,
    but the ''out'' tensor is expected to be of type int32. The ''input'' tensor needs
    to be converted to int32 before being assigned to ''out''. Therefore, Left : type(input)
    should be equal to Right : int32. Also, the type of ''out'' should be equal to
    type(input) to ensure that they are of the same type.'
  target: result type Float can't be cast to the desired output type Int
  txt: (type(input)==int32) or (type(out)==type(input))
- cot: 'The issue seems to be related to the ''input'' and ''out'' tensors. As per
    the error, there is an attempt to resize a tensor that is not resizable. The dimensions
    of the ''input'' tensor are [6, 8] and the ''out'' tensor are [2, 8]. It appears
    that we''re trying to resize the ''input'' tensor to match the ''out'' tensor.
    This could be violating the tensor resizing rules. Therefore, Left : len(input.shape)
    or input.shape[i]. The operation implies that the dimensions should be equal,
    so Op : ==, and Right : len(out.shape) or out.shape[i].'
  target: Trying to resize storage that is not resizable
  txt: (out.rank == input.rank) and (all(input.shape[i] == out.shape[i] for i in range(len(input.shape))))
time_cost: 1655.1918971538544
title: torch._C._special.special_bessel_y1
tokens_used: 11587
trained: true
