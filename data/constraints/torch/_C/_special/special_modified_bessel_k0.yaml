constraints:
  input:
    default: null
    dtype: float16,float32,float64,uint8,complex64,complex128,int8,int16,int32,int64,bool
    init: false
    required: true
  out:
    default: null
    dtype: float16,float32,float64,uint8,complex64,complex128,int8,int16,int32,int64,bool
    init: false
    required: false
infered_history: []
infered_times: 17
package: torch
pass_rate: 1.0
rules:
- cot: 'The error is due to an attempt to resize a tensor (''out'') that can''t be
    resized. Given the values of ''input'' and ''out'', it''s clear that ''out'' does
    not have the same shape as ''input''. A constraint that should be applied to prevent
    the error is that the shape of ''out'' should be the same as the shape of ''input''.
    Therefore, left: out.shape, out.rank op: == right: input.shape, input.rank.'
  target: Trying to resize storage that is not resizable
  txt: (len(input) <= len(out)) and (all(out.shape[i] == input.shape[i] for i in range(out.rank)))
- cot: 'The error occurs because the output type is ''Long'' while the calculation
    result is ''Float'', which cannot be converted to ''Long'' directly. Let''s see
    what the args were. The ''out'' tensor is of ''Long'' type, and the ''input''
    tensor is of ''int8'' type. To not trigger the error, the type of the result of
    operations on ''input'' tensor should be ''Long'', not ''Float''. Therefore, Left
    : input.  Op : == Right : int64. Also, the ''out'' tensor''s dtype
    should be the same as the ''input'' tensor''s dtype. Therefore, Left : out. 
    Op : == Right : input. '
  target: result type Float can't be cast to the desired output type Bool
  txt: (input.dtype==out.dtype) and ((out.dtype == float) and (out .dtype ==
    input .dtype))
time_cost: 554.8564732074738
title: torch._C._special.special_modified_bessel_k0
tokens_used: 9741
trained: true
