constraints:
  n:
    default: null
    dtype: float16,float32,float64,uint8,complex64,complex128,int8,int16,int32,int64,bool
    init: false
    required: true
  out:
    default: 'null'
    dtype: float16,float32,float64,uint8,complex64,complex128,int8,int16,int32,int64,bool
    init: false
    required: false
  x:
    default: null
    dtype: float16,float32,float64,uint8,complex64,complex128,int8,int16,int32,int64,bool
    init: false
    required: true
infered_history: []
infered_times: 14
package: torch
pass_rate: 0.48
rules:
- cot: 'Error is triggered because of trying to resize storage that is not resizable.
    In this case, the storage is likely referred to ''out'' tensor. The ''out'' tensor
    is not resizable because its shape is already defined. In this operation, the
    ''out'' tensor''s shape should match the operation results. Here, the result shape
    is ''x.shape'' or ''n.shape''. Therefore, left : out.shape, out.rank op : == right
    : x.shape, x.rank or n.shape, n.rank.'
  target: Trying to resize storage that is not resizable
  txt: out.rank==x.rank and all(out.shape[i]==x.shape[i] for i in range(out.rank))
    and out.rank==n.rank and all(out.shape[i]==n.shape[i] for i in range(out.rank))
- cot: The error is due to a type mismatch. The result type of 'n' is a complex number
    (ComplexFloat) which can't be converted to the desired output type (Float). To
    prevent this error, 'n' should be of type Float. Therefore,
  target: result type ComplexFloat can't be cast to the desired output type Float
  txt: (type(x)==Float) or (type(out)==Float)
time_cost: 4858.959731340408
title: torch._C._special.special_hermite_polynomial_h
tokens_used: 8198
trained: true
