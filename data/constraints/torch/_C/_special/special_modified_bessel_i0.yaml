constraints:
  input:
    default: null
    dtype: float16,float32,float64,uint8,complex64,complex128,int8,int16,int32,int64,bool
    init: false
    required: true
  out:
    default: null
    dtype: float16,float32,float64,uint8,complex64,complex128,int8,int16,int32,int64,bool
    init: false
    required: false
infered_history: []
infered_times: 25
package: torch
pass_rate: 0.88
rules:
- cot: 'The error is due to the function "modified_bessel_i0_cpu" not being implemented
    for the data type ''Half'', which corresponds to float16. In this case, ''input''
    is a tensor of type float16. To prevent this error, the input tensor''s data type
    should be changed to a type that is supported by the "modified_bessel_i0_cpu"
    function. The data types that are supported by this function can be found in the
    documentation of the function. Therefore, the logical relationship constraints
    could be:'
  target: '"modified_bessel_i0_cpu" not implemented for ''Half'''
  txt: (input.dtype != float16)
- cot: "The error occurs because the result type Float cannot be cast to the Long\
    \ type. The input tensor has an int64 type while the output tensor has a list\
    \ of int64s. The dtype of the input tensor and the output tensor should be consistent.\
    \ Also, the shape of the input tensor and output tensor should be consistent as\
    \ well. \n\nThe constraints should be as follows:\n\n1) The dtypes of the input\
    \ and output tensors should be the same."
  target: result type Float can't be cast to the desired output type Long
  txt: input.shape == out.shape
time_cost: 1225.1027126312256
title: torch._C._special.special_modified_bessel_i0
tokens_used: 13612
trained: true
