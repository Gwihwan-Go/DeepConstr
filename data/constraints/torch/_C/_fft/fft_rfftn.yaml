constraints:
  input:
    default: 'null'
    dtype: float16,float32,float64,uint8,complex64,complex128,int8,int16,int32,int64,bool
    init: false
    required: true
  norm:
    default: forward
    dtype: Literal['forward', 'backward', 'ortho']
    init: false
    required: false
  out:
    default: 'null'
    dtype: float16,float32,float64,uint8,complex64,complex128,int8,int16,int32,int64,bool
    init: false
    required: false
infered_history: []
infered_times: 4
package: torch
pass_rate: 0.0
rules:
- cot: 'The error arises because the rfftn function expects a complex tensor, but
    it received a float tensor as output. In the given values, we see that both ''input''
    and ''out'' tensors are of float type. So, the output tensor type should be changed
    to complex. Therefore, the constraint should be: Left : type(out), Op : ==, Right
    : complex.'
  target: rfftn expects a complex output tensor, but got Float
  txt: type(out)==complex
- cot: 'The error seems to be triggered by invalid configuration parameters in the
    MKL FFT operation. In this case, the input tensor and the out tensor have different
    dimensions and data types. Also, the norm argument is set to ''ortho''. So, the
    constraints should be that input tensor and out tensor should have same dimensions
    and data types. Also, the norm parameter must be a valid option for MKL FFT. Therefore,
    Left : input.dim, Op : ==, and Right : out.dim should be corrected. Also, Left
    : input.dtype, Op : ==, and Right : out.dtype should be corrected. Also, check
    if norm is in the valid options for MKL FFT.'
  target: 'MKL FFT error: Intel MKL DFTI ERROR: Invalid configuration parameters'
  txt: (input.dim == out.dim)
- cot: 'This error arises due to an attempt to resize a storage that is not resizable.
    Examining the values provided, there are two tensors ''input'' and ''out''. If
    ''out'' is the storage, it may not be resizable, so the shape of ''input'' and
    ''out'' should be the same from the beginning. Also, the norm should be either
    ''forward'' or ''backward''. Thus:


    1. The shape of ''input'' and ''out'' should be the same.'
  target: Trying to resize storage that is not resizable
  txt: input.shape == out.shape
- cot: 'The error is due to the fact that the dtype of the input tensor is ''Half''
    (float16), which is not supported. Therefore, the dtype of the input tensor must
    be changed to a supported dtype. Additionally, the dtype of the output tensor
    is ''complex64'', which may not be compatible with the input dtype. Hence, the
    dtype of the input and output tensors should be compatible. Therefore, Left :
    input.dtype, Op : !=, and Right : TensorDType.float16; and Left : input.dtype,
    Op : ==, Right : out.dtype'
  target: Unsupported dtype Half
  txt: input.dtype == out.dtype
time_cost: 227.76398086547852
title: torch._C._fft.fft_rfftn
tokens_used: 2914
