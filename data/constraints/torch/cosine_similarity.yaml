constraints:
  dim:
    default: 1
    dtype: int
    init: false
    required: false
  eps:
    default: 1.0e-08
    dtype: float
    init: false
    required: false
  x1:
    default: null
    dtype: float16,float32,float64,uint8,complex64,complex128,int8,int16,int32,int64,bool
    init: false
    required: true
  x2:
    default: null
    dtype: float16,float32,float64,uint8,complex64,complex128,int8,int16,int32,int64,bool
    init: false
    required: true
infered_history: []
infered_times: 22
package: torch
pass_rate: 0.97
rules:
- cot: 'The error here is due to an out of range dimension. The variable ''dim'' corresponds
    to the dimension to reduce. It says ''dim'' must be in the range of -1 to 0, but
    it got -456 which is outside of the valid range. Therefore, ''dim'' should be
    corrected. It says it should fall between -1 and 0, so Operation : >= and <=;
    and Right : -1 and 0 respectively.'
  target: Dimension out of range (expected to be in range of [-1, 0], but got -456)
  txt: -1<=dim
- cot: 'Error is triggered because size of tensors at non-singleton dimension 9 doesn''t
    match. What the args were? The tensors x1 and x2 have different sizes at non-singleton
    dimension 9. Broadcasting in tensor operations requires that the trailing dimensions
    of the tensors are either 1 or the same. We start from the last dimension because
    broadcasting aligns dimensions from the end. Therefore, we can revise the constraints
    as follows:'
  target: The size of tensor a (4) must match the size of tensor b (7) at non-singleton
    dimension 9
  txt: all(x1.shape[i] == x2.shape[i] or x1.shape[i] == 1 or x2.shape[i] == 1 for
    i in range(-1, -min(len(x1.shape), len(x2.shape))-1, -1))
- cot: 'The error occurs because the function is expecting floating point tensors,
    but received a complex tensor. Let''s see what the args were. It appears the data
    type of ''x1'' tensor is complex128 and the data type of ''x2'' tensor is float32.
    To prevent this error in the future and generate constraints that do not trigger
    it, we need to ensure that both input tensors ''x1'' and ''x2'' are of floating
    point data type.


    The constraints for the ''x1'' and ''x2'' parameters can be expressed as:'
  target: expected common dtype to be floating point, yet common dtype is ComplexDouble
  txt: '''x1''.dtype in [float32, float64] and ''x2''.dtype in [float32, float64]'
time_cost: 1618.2177078723907
title: torch.cosine_similarity
tokens_used: 14061
trained: true
