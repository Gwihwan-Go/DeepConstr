constraints:
  condition:
    dtype: float16,float32,float64,uint8,complex64,complex128,int8,int16,int32,int64,bool
    init: false
    required: true
  input:
    default: null
    dtype: float16,float32,float64,uint8,complex64,complex128,int8,int16,int32,int64,bool
    init: false
    required: true
  other:
    default: null
    dtype: float16,float32,float64,uint8,complex64,complex128,int8,int16,int32,int64,bool
    init: false
    required: true
  out:
    default: null
    dtype: float16,float32,float64,uint8,complex64,complex128,int8,int16,int32,int64,bool
    init: false
    required: true
infered_history: []
infered_times: 29
package: torch
pass_rate: 1.0
rules:
- cot: 'Error is triggered because the ''condition'' tensor is not a boolean tensor.
    It seems the tensor ''condition'' has dtype float32, but it should be a boolean
    tensor. Therefore, Left : condition.dtype, Op : ==, and Right : boolean.'
  target: where expected condition to be a boolean tensor, but got a tensor with dtype
    Float
  txt: condition.dtype == boolean
- cot: 'Error is triggered because we are trying to resize storage that is not resizable.
    Let''s see what the args were. The given values indicate that the ''condition'',
    ''input'', ''other'', and ''out'' tensors have different shapes. Therefore, the
    ''out'' tensor shape should match the shape of the ''input'' tensor. Also, the
    ''condition'' and ''other'' tensors should have shapes that are compatible with
    the ''input'' tensor for the operation. Therefore, Left : out.shape, condition.shape,
    other.shape, Op : ==, and Right : input.shape.'
  target: Trying to resize storage that is not resizable
  txt: out.shape == input.shape and condition.shape == input.shape and other.shape
    == input.shape
- cot: 'Error is triggered because of dynamic casting issue. Let''s see what the args
    were. The error message indicates that dynamic casting is not allowed in this
    case. I guess the data type of ''input'' and ''other'' tensor should be matched
    with ''out'' tensor. Therefore, left : input.dtype, other.dtype op : == right
    : out.dtype'
  target: '!needs_dynamic_casting<func_t>::check(iter) INTERNAL ASSERT FAILED at "../aten/src/ATen/native/cpu/Loops.h":310,
    please report a bug to PyTorch.'
  txt: input.dtype == out.dtype and other.dtype == out.dtype
time_cost: 5532.683363437653
title: torch.where
tokens_used: 19645
trained: true
