alias: torch.atan2
constraints:
  input:
    default: null
    dtype: float16,float32,float64,uint8,complex64,complex128,int8,int16,int32,int64,bool
    init: false
    required: true
  other:
    default: null
    dtype: float16,float32,float64,uint8,complex64,complex128,int8,int16,int32,int64,bool
    init: false
    required: true
  out:
    default: null
    dtype: float16,float32,float64,uint8,complex64,complex128,int8,int16,int32,int64,bool
    init: false
    required: false
infered_history: []
infered_times: 56
package: torch
pass_rate: 0.22
rules:
- cot: "The error is due to an attempt to resize a non-resizable storage. Based on\
    \ the given values, 'input', 'other' and 'out' are tensors with specific dimensions.\
    \ The error may occur if there's an attempt to resize these tensors beyond their\
    \ defined dimensions. Therefore, the dimensions of the tensors should be verified\
    \ before any operation. \n\nLet's consider the tensor dimensions: 'input' has\
    \ dimensions [5, 1, 5, 1, 1], 'other' has dimensions [5, 1, 5] and 'out' has dimensions\
    \ [1, 2, 1]. The dimensions of 'out' should be consistent with the dimensions\
    \ of 'input' and 'other' after the operation. \n\nTherefore, the constraints would\
    \ be:"
  target: Trying to resize storage that is not resizable
  txt: (out.rank==input.rank and all(out.shape[i]==input.shape[i] for i in range(out.rank)))
    and ((all(out.shape[i]==input.shape[i] for i in range(out.rank))) and (len(input.shape)
    == len(other.shape)))
- cot: 'The error is triggered because the output tensor has a different datatype
    (Short) compared to the input tensor (Float). What the args were? In this case,
    the input tensor has dtype float32 and the other tensor has dtype int16. The output
    tensor is expected to be of the same type as the ''other'' tensor, but it currently
    is of type float. Therefore, Left : type(input) or type(out). Op : == Right :
    type(other)'
  target: result type Float can't be cast to the desired output type Short
  txt: (type(input)==type(out)) and (type(input)==type(other))
- cot: 'Error is triggered because size of tensors at non-singleton dimension 4 doesn''t
    match. Let''s see what the args were? the two tensors matching problem at non-singleton
    dimension looks like broadcasting request. Broadcasting in tensor operations requires
    that the trailing dimensions of the tensors are either 1 or the same. We start
    from the last dimension because broadcasting aligns dimensions from the end. Therefore,
    we can revise the constraints as follows:'
  target: The size of tensor a (4) must match the size of tensor b (6) at non-singleton
    dimension 4
  txt: all(input.shape[i] == other.shape[i] or input.shape[i] == 1 or other.shape[i]
    == 1 for i in range(-1, -min(len(input.shape), len(other.shape))-1, -1))
- cot: 'The error is due to the ''atan2_cpu'' function being not implemented for complex
    numbers. The data type of ''input'', ''other'', and ''out'' tensors is ''complex64'',
    which is not compatible with the ''atan2_cpu'' function. Therefore, the data type
    of these tensors should be corrected to a type that is compatible with ''atan2_cpu''.
    It is usually implemented for float or integer types. So, Op : !=, Right : ''complex64''
    and type(<symbol>) should be either int or float.'
  target: '"atan2_cpu" not implemented for ''ComplexFloat'''
  txt: (input.dtype != 'ComplexFloat') and (type(out) != 'complex64')
time_cost: 26491.9864051342
title: torch.atan2
tokens_used: 37780
trained: true
