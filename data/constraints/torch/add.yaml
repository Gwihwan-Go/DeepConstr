alias: torch.add
constraints:
  alpha:
    default: 1
    dtype: int
    init: false
    required: false
  input:
    default: null
    dtype: float16,float32,float64,uint8,complex64,complex128,int8,int16,int32,int64,bool
    init: false
    required: true
  other:
    default: null
    dtype: float16,float32,float64,uint8,complex64,complex128,int8,int16,int32,int64,bool,int32,int64,int8,int16
    init: false
    required: true
  out:
    default: null
    dtype: float16,float32,float64,uint8,complex64,complex128,int8,int16,int32,int64,bool
    init: false
    required: false
infered_history: []
infered_times: 10
package: torch
pass_rate: 1.0
rules:
- cot: 'The error is triggered because result type ComplexFloat cannot be cast to
    the Float. Let''s see the what''s args were. The dtype of ''input'' and ''other''
    is inconsistent, each for float32, complex64. Therefore, the dtypes of two arguments
    should be consistent. Left : type(input), op : ==, comparator : type(other) or
    type(out)'
  target: result type ComplexFloat can't be cast to the desired output type Float
  txt: (type(other)==type(out)) and (type(input)==type(other))
- cot: The error is due to the mismatch in shape and rank between 'out' tensor and
    'input' tensor. The 'out' tensor is not resizable. Hence, in the initial stage,
    the 'out' tensor should be defined with a shape and rank that matches with the
    'input' tensor. The values provided indicate that the shape of 'input' tensor
    is [2, 10, 4, 7, 2, 8, 7] and the shape of 'out' tensor is [9, 3, 7, 2, 3, 10].
  target: Trying to resize storage that is not resizable
  txt: (other.shape == input.shape) and (out.rank == input.rank and all(out.shape[i]
    == input.shape[i] for i in range(out.rank)))
time_cost: 4068.53488445282
title: torch.add
tokens_used: 7696
trained: true
