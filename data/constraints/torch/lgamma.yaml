alias: torch.lgamma
constraints:
  input:
    default: null
    dtype: float16,float32,float64,uint8,complex64,complex128,int8,int16,int32,int64,bool
    init: false
    required: true
  out:
    default: null
    dtype: float16,float32,float64,uint8,complex64,complex128,int8,int16,int32,int64,bool
    init: false
    required: false
infered_history: []
infered_times: 7
package: torch
pass_rate: 0.95
rules:
- cot: 'The error indicates that there''s an attempt to resize a tensor that''s not
    resizable. The input tensor has a shape of [6, 8, 6, 6, 1, 3, 4, 1, 3, 2] and
    the output tensor has a shape of [8, 2, 1]. This suggests that the output tensor
    is being resized to accommodate the input tensor, which is causing the error.
    Therefore, the size or shape of the ''input'' tensor and ''out'' tensor should
    be the same or within the capacity of ''out'' tensor. Left: len(input), Op: ''<='',
    and Right: len(out).'
  target: Trying to resize storage that is not resizable
  txt: (all(out.shape[i] == input.shape[i] for i in range(len(input.shape)))) and
    (len(input) <= len(out))
time_cost: 714.0076327323914
title: torch.lgamma
tokens_used: 4639
trained: true
