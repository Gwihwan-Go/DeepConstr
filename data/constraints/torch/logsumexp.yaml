constraints:
  dim:
    default: null
    dtype: int
    init: false
    required: false
  input:
    default: null
    dtype: float16,float32,float64,uint8,complex64,complex128,int8,int16,int32,int64,bool
    init: false
    required: true
  keepdim:
    default: false
    dtype: bool
    init: false
    required: false
  out:
    default: null
    dtype: float16,float32,float64,uint8,complex64,complex128,int8,int16,int32,int64,bool
    init: false
    required: false
infered_history: []
infered_times: 14
package: torch
pass_rate: 0.93
rules:
- cot: 'The error suggests that an attempt was made to resize storage that is not
    resizable. Looking at the provided values, ''input'' is a tensor of type int16
    and of size [10, 9], ''dim'' is set to 0, ''keepdim'' is False, and ''out'' is
    a tensor of type float32 with no elements. Resizing may have been attempted due
    to the difference in sizes or types of the ''input'' and ''out'' tensors. Therefore,
    the constraints needed would be to ensure the ''out'' tensor is resizable and
    matches the type and size of the ''input'' tensor. Thus, Left: out, Op: ''is'',
    Right: ''Resizable'' and Left: out.size(), Op: ''=='', Right: input.size() and
    Left: out.dtype, Op: ''=='', Right: input.dtype.'
  target: Trying to resize storage that is not resizable
  txt: out.size() == input.size()
- cot: 'The given error is thrown because the ''dim'' value is out of the valid range
    for the given tensor. According to the input tensor''s shape, the valid range
    for ''dim'' should be between -2 and 1 (both inclusive). However, the provided
    ''dim'' value is 6, which is outside the valid range.


    To avoid such an error, we need to ensure that the ''dim'' value is within the
    allowed range for the given tensor. Here, the shape of the tensor is [9, 8], so
    the range of valid dimensions is [-2, 1]. Therefore, the ''dim'' value should
    satisfy the following constraint:'
  target: Dimension out of range (expected to be in range of [-2, 1], but got 6)
  txt: dim >= -len(input.shape) and dim < len(input.shape)
- cot: 'The error occurs because the function ''logsumexp()'' requires a floating
    point type for the result tensor, but it received an integer type instead. Let''s
    see what the args were. It seems the ''out'' tensor is of integer type, which
    is causing the problem. Therefore, the type of ''out'' tensor needs to be corrected.
    Left : out.dtype, which is the type of the ''out'' tensor. It should be a floating
    point type, so Op : ==, and Right : float.'
  target: 'logsumexp(): Expected floating point type for result tensor, but got: ComplexFloat'
  txt: out.dtype == float
time_cost: 442.25678849220276
title: torch.logsumexp
tokens_used: 8869
trained: true
