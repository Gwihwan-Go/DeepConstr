alias: torch.mul
constraints:
  input:
    default: null
    dtype: float16,float32,float64,uint8,complex64,complex128,int8,int16,int32,int64,bool
    init: false
    required: true
  other:
    default: null
    dtype: float16,float32,float64,uint8,complex64,complex128,int8,int16,int32,int64,bool,int32,int64,int8,int16
    init: false
    required: true
  out:
    default: null
    dtype: float16,float32,float64,uint8,complex64,complex128,int8,int16,int32,int64,bool
    init: false
    required: false
infered_history: []
infered_times: 32
package: torch
pass_rate: 1.0
rules:
- cot: 'The error occurs due to the mismatch of the expected output type and the actual
    result type. The function expects a boolean type but got a float type. Let''s
    see what the args were. When ''input'' and ''other'' are float type, ''out'' should
    also be float type to prevent this error. Therefore, Left : out.dtype Op : ==
    Right : input.dtype, float'
  target: result type Float can't be cast to the desired output type Bool
  txt: (other.dtype == out.dtype) and ((input.dtype == out.dtype) or (out.dtype==float))

- cot: 'The error is triggered because ''out'' tensor is trying to resize its storage.
    From the values, we can see that ''out'' tensor has a shape of [4] while ''input''
    and ''other'' tensors have a shape of [10]. The operation might be expecting ''out''
    tensor to have the same shape as ''input'' and ''other'' tensors. Therefore, Left
    : out.shape, out.rank. Op : ==. Right : input.shape, input.rank.'
  target: Trying to resize storage that is not resizable
  txt: (out.rank==input.rank and all(out.shape[i]==input.shape[i] for i in range(out.rank)))
    or ((len(out) >= max(len(input), len(other))) and (all(out.shape[i]==input.shape[i]
    for i in range(out.rank))))
time_cost: 2447.3052730560303
title: torch.mul
tokens_used: 17430
trained: true
