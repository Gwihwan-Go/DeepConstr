constraints:
  logits:
    default: null
    dtype: float16,float32,float64,uint8,complex64,complex128,int8,int16,int32,int64,bool
    init: false
    required: true
  name:
    default: null
    dtype: str
    init: false
    required: false
  num_samples:
    default: null
    dtype: float16,float32,float64,uint8,complex64,complex128,int8,int16,int32,int64,bool
    init: false
    required: true
  seed:
    default: 0
    dtype: int
    init: false
    required: false
  seed2:
    default: 0
    dtype: int
    init: false
    required: false
infered_history:
- 4
- 4
- 3
infered_times: 13
package: tf
pass_rate: 0.32
rules:
- cot: 'The error is triggered because the operation expects an int32 tensor but is
    getting a float tensor. Looking at the values, ''logits'' and ''num_samples''
    are both float tensors. The ''num_samples'' tensor seems to be the problem as
    it is expected to be an integer tensor for the Multinomial operation. Therefore,
    the data type of num_samples should be corrected. Left : num_samples.dtype, which
    is the type of tensor num_samples. It says that should be equal to int32, so Op
    : ==, and Right : int32.'
  target: 'cannot compute Multinomial as input #1(zero-based) was expected to be a
    int32 tensor but is a float tensor [Op:Multinomial] name:'
  txt: num_samples.dtype == int32
- cot: 'The error is due to the fact that logits is not a matrix. The rank of a tensor
    is the length of its shape, and the rank of a matrix is 2. Therefore, the Left
    : len(logits.shape) should be corrected to 2. Ops : ''=='', Right : 2. Also, it
    seems that num_samples is not scalar, but it should be. So, num_samples.dim should
    be 0. Ops : ''=='', Right : 0.'
  target: 'logits should be a matrix, got shape [8,6,6,1,3,1,1,3] [Op:Multinomial]
    name:'
  txt: len(logits.shape) == 2 and num_samples.dim == 0
time_cost: 466.53914189338684
title: tf.raw_ops.Multinomial
tokens_used: 8326
