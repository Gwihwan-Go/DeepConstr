constraints:
  name:
    default: null
    dtype: str
    init: false
    required: false
  x:
    default: null
    dtype: float16,float32,float64,uint8,complex64,complex128,int8,int16,int32,int64,bool
    init: false
    required: true
  y:
    default: null
    dtype: float16,float32,float64,uint8,complex64,complex128,int8,int16,int32,int64,bool
    init: false
    required: true
infered_history:
- 4
- 3
- 1
- 4
infered_times: 13
package: tf
pass_rate: 1.0
rules:
- cot: 'The error is generated because the function is attempting to perform an operation
    between an int32 tensor and a float tensor. However, both tensors in the generated
    arguments must have the same data type. Looking at the arguments, tensor ''x''
    is of type int16 and tensor ''y'' is float32. Therefore, the data type of tensor
    ''x'' should be matched with tensor ''y''.  So, Left : type(x). It says that should
    be equal to the datatype of tensor y, so Op : ==, and Right : type(y).'
  target: 'cannot compute LessEqual as input #1(zero-based) was expected to be a int32
    tensor but is a float tensor [Op:LessEqual] name:'
  txt: type(x)==type(y)
- cot: 'The error is due to the operation being applied to tensors that have a rank
    greater than 5. The maximum rank allowed for the operation is 5, but the tensors
    x and y have ranks of 5 and 7 respectively. The rank of a tensor is the number
    of dimensions it has. Therefore, we need to ensure that the rank of x and y is
    less than or equal to 5. So, the Left : x.rank, Op : <=, Right : 5 and Left :
    y.rank, Op : <=, Right : 5.'
  target: 'Input for dynamic binary or n-ary op lowering was of a rank greater than
    5 [Op:LessEqual] name:'
  txt: ((type(x) == type(y)) and (((x.rank <= 5)) or ((y.rank <= 5)))) or (((x.rank
    <= 5)) and ((y.rank <= 5))) or ((type(x) == type(y)) and (((x.rank <= 5)) or ((y.rank
    <= 5))))
- cot: 'From the given values, the error is due to the attribute ''T'' of the tensors
    ''x'' and ''y'' being of type complex64, which is not in the list of allowed types:
    float, double, int32, uint8, int16, int8, int64, bfloat16, uint16, half, uint32,
    uint64. Therefore, the type of ''x'' and ''y'' should be corrected to match one
    of the allowed types. Op: in, and Right: [float, double, int32, uint8, int16,
    int8, int64, bfloat16, uint16, half, uint32, uint64].'
  target: "Value for attr 'T' of complex64 is not in the list of allowed values: float,\
    \ double, int32, uint8, int16, int8, int64, bfloat16, uint16, half, uint32, uint64\n\
    \ ; NodeDef: ; Op z:bool; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32,\
    \ DT_UINT8, DT_INT16, DT_INT8, DT_INT64, DT_BFLOAT16, DT_UINT16, DT_HALF, DT_UINT32,\
    \ DT_UINT64]> [Op:LessEqual] name:"
  txt: type(x) in ["float", "double", "int32", "uint8", "int16", "int8", "int64",
    "bfloat16", "uint16", "half", "uint32", "uint64"] and type(y) in ["float", "double",
    "int32", "uint8", "int16", "int8", "int64", "bfloat16", "uint16", "half", "uint32",
    "uint64"]
- cot: 'The error is due to the shapes of ''''x'''' and ''''y'''' not being broadcastable.
    Broadcasting in tensor operations requires that the trailing dimensions of the
    tensors are either 1 or the same. So, the constraint should be that for each dimension
    starting from the last, the size of the dimension in ''''x'''' should be equal
    to the size of the dimension in ''''y'''' or one of them should be 1. We start
    from the last dimension because broadcasting aligns dimensions from the end. Therefore,
    we can revise the constraints as follows:'
  target: 'required broadcastable shapes [Op:LessEqual] name:'
  txt: all(x.shape[i] == y.shape[i] or x.shape[i] == 1 or y.shape[i] == 1 for i in
    range(-1, -min(len(x.shape), len(y.shape))-1, -1))
time_cost: 1301.8552329540253
title: tf.raw_ops.LessEqual
tokens_used: 9002
