constraints:
  name:
    default: null
    dtype: str
    init: false
    required: false
  x:
    default: null
    dtype: float16,float32,float64,uint8,complex64,complex128,int8,int16,int32,int64,bool
    init: false
    required: true
  y:
    default: null
    dtype: float16,float32,float64,uint8,complex64,complex128,int8,int16,int32,int64,bool
    init: false
    required: true
infered_history: []
infered_times: 0
package: tf
pass_rate: 0.96
rules:
- cot: 'The error is due to incompatible shapes of tensors ''x'' and ''y''. The shape
    of ''x'' is [9, 2, 9, 8, 3, 8, 6] and the shape of ''y'' is [4, 1, 3, 2, 8, 2,
    6, 6, 8]. Therefore, Left : len(x), x.shape should be corrected. It says incompatible
    shapes with ''y'', so Op : ==, and Right : len(y), y.shape'
  target: 'Incompatible shapes: vs.  name:'
  txt: (len(x) == len(y)) and (all(x.shape[i]==y.shape[i] for i in range(len(x))))
- cot: 'The error arises because the function is trying to perform an operation on
    a int32 tensor and a complex128 tensor. However, both tensors in the argument
    must have the same data type. Let''s see what the args were. ''x'' tensor is int32,
    but the ''y'' tensor is of complex128, which is incorrect. Therefore, Left : y.dtype,
    which is the type of tensor y, should be corrected. It says that should be equal
    to the datatype of tensor x, so Op : ==, and Right : x.dtype.'
  target: 'cannot compute TruncateMod as input #1(zero-based) was expected to be a
    int32 tensor but is a complex128 tensor name:'
  txt: y.dtype==x.dtype
- cot: 'The error is due to incorrect datatype for ''T'', Instead of int16 it should
    be in the list of allowed datatypes: int32, int64, bfloat16, half, float, double.
    Therefore, T.dtype of both ''x'' Tensor and ''y'' Tensor should be corrected.
    The constraint should ensure that ''T'' should be one of the allowed datatypes.
    Therefore, Op : in, and Right : [int32, int64, bfloat16, half, float, double].'
  target: "Value for attr 'T' of int16 is not in the list of allowed values: int32,\
    \ int64, bfloat16, half, float, double\n ; NodeDef: ; Op z:T; attr=T:type,allowed=>\
    \ name:"
  txt: x.dtype in [int32, int64, bfloat16, half, float, double] and y.dtype in
    [int32, int64, bfloat16, half, float, double]

- cot: 'The error occurs due to the unavailability of a device for running the TruncateMod
    operation for the data type DT_HALF. The available devices for DT_HALF are ''XLA_CPU_JIT''
    and ''XLA_GPU_JIT''. Therefore, the operation should run on one of these devices.
    So, the Left : x.dtype or y.dtype should be corrected to match DT_FLOAT, DT_DOUBLE,
    DT_INT32, DT_INT64, DT_BFLOAT16. Op : in, and Right : [''XLA_CPU_JIT'', ''XLA_GPU_JIT''].'
  target: "Could not find device for node: = TruncateMod[T=DT_HALF]\nAll kernels registered\
    \ for op TruncateMod:\n device='XLA_CPU_JIT'; T in [DT_FLOAT, DT_DOUBLE, DT_INT32,\
    \ DT_INT64, DT_BFLOAT16, DT_HALF]\n device='XLA_GPU_JIT'; T in [DT_FLOAT, DT_DOUBLE,\
    \ DT_INT32, DT_INT64, DT_BFLOAT16, DT_HALF]\n device='DEFAULT'; T in [DT_INT32]\n\
    \ device='GPU'; T in [DT_INT32]\n device='CPU'; T in [DT_DOUBLE]\n device='CPU';\
    \ T in [DT_FLOAT]\n device='CPU'; T in [DT_INT64]\n device='CPU'; T in [DT_INT32]\n\
    \ [Op:TruncateMod] name:"
  txt: x.dtype in ["DT_FLOAT", "DT_DOUBLE", "DT_INT32", "DT_INT64", "DT_BFLOAT16"]
    and y.dtype in ["DT_FLOAT", "DT_DOUBLE", "DT_INT32", "DT_INT64", "DT_BFLOAT16"]

time_cost: 0.001026153564453125
title: tf.raw_ops.TruncateMod
tokens_used: 0
trained: true
