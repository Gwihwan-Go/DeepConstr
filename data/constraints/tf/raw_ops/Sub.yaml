constraints:
  name:
    default: null
    dtype: str
    init: false
    required: false
  x:
    default: null
    dtype: float16,float32,float64,uint8,complex64,complex128,int8,int16,int32,int64,bool
    init: false
    required: true
  y:
    default: null
    dtype: float16,float32,float64,uint8,complex64,complex128,int8,int16,int32,int64,bool
    init: false
    required: true
infered_history:
- 4
- 4
- 1
- 4
- 2
infered_times: 16
package: tf
pass_rate: 0.12
rules:
- cot: 'The error is due to a mismatch between the expected and actual data type of
    the second input for the Subtraction operation. The function expects a complex64
    tensor, but it is receiving a complex128 tensor instead. Although both tensors
    x and y are of complex64 type in the error provided, the error message suggests
    that the second input is a complex128 tensor. This discrepancy could be due to
    an internal operation or transformation applied to y before the Subtraction operation.
    Therefore, to prevent this error from occurring again, the data type of tensor
    y should be kept consistent with the data type of tensor x throughout all operations.
    Also, any internal operations performed on y should not change its data type from
    complex64. Hence, the constraint should be:'
  target: 'cannot compute Sub as input #1(zero-based) was expected to be a float tensor
    but is a int32 tensor [Op:Sub] name:'
  txt: y.dtype==x.dtype and len(y.shape)==len(x.shape)
- cot: 'The error occurs because the shapes of ''x'' and ''y'' are not broadcastable
    for the subtraction operation. The broadcasting rules require that the trailing
    dimensions of ''x'' and ''y'' must either be equal or one of them must be 1. In
    this case, the trailing dimensions of ''x'' and ''y'' are 7 and 8, respectively,
    which are not equal and neither of them is 1. Therefore, the shapes of ''x'' and
    ''y'' must be corrected to become broadcastable. So, Left : len(x) or len(y).
    Ops: ''=='', Right : 1 or Left : len(x), Ops: ''=='', Right : len(y).'
  target: 'required broadcastable shapes [Op:Sub] name:'
  txt: len(x) == 1 or len(y) == 1 or len(x) == len(y)
- cot: 'The error is thrown because the attribute ''T'' of the tensors ''x'' and ''y''
    are of boolean type, but the allowed types are bfloat16, half, float, double,
    uint8, int8, uint16, int16, int32, int64, complex64, complex128, uint32, uint64.
    Therefore, the x.dtype and y.dtype should be corrected to match one of the allowed
    types. The operation Op : in and Right : [bfloat16, half, float, double, uint8,
    int8, uint16, int16, int32, int64, complex64, complex128, uint32, uint64].'
  target: "Value for attr 'T' of bool is not in the list of allowed values: bfloat16,\
    \ half, float, double, uint8, int8, uint16, int16, int32, int64, complex64, complex128,\
    \ uint32, uint64\n ; NodeDef: ; Op z:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF,\
    \ DT_FLOAT, DT_DOUBLE, DT_UINT8, DT_INT8, DT_UINT16, DT_INT16, DT_INT32, DT_INT64,\
    \ DT_COMPLEX64, DT_COMPLEX128, DT_UINT32, DT_UINT64]> [Op:Sub] name:"
  txt: x.dtype in ["bfloat16", "half", "float", "double", "uint8", "int8", "uint16",
    "int16", "int32", "int64", "complex64", "complex128", "uint32", "uint64"] and
    y.dtype in ["bfloat16", "half", "float", "double", "uint8", "int8", "uint16",
    "int16", "int32", "int64", "complex64", "complex128", "uint32", "uint64"]
- cot: 'The error indicates that the operation cannot compute Sub because one of the
    inputs was expected to be a complex64 tensor but is a complex128 tensor. This
    suggests that the types of x and y are inconsistent with the operation''s requirements.
    Let''s see what the arguments were. x and y were tensors of int32. However, the
    operation requires complex64. Therefore, the types of x and y should be corrected.
    Ops : "==", Left : x.dtype, y.dtype, Right : complex64.'
  target: 'Incompatible shapes: [7,1,1] vs. [2,10,1] [Op:Sub] name:'
  txt: (y.dtype == complex64) and (len(x) == len(y)) and (y.dtype == complex64)
- cot: 'The error occurs due to a tensor rank greater than 5. The tensors x and y
    both have a rank greater than 5. For the operation not to trigger the error, the
    tensor rank should be less than or equal to 5. Therefore, Left: rank(x), Op: <=,
    and Right: 5. Similarly, Left: rank(y), Op: <=, and Right: 5.'
  target: 'Input for dynamic binary or n-ary op lowering was of a rank greater than
    5 [Op:Sub] name:'
  txt: (rank(x) <= 5) and (rank(y) <= 5)
time_cost: 1945.9708223342896
title: tf.raw_ops.Sub
tokens_used: 9594
trained: true
