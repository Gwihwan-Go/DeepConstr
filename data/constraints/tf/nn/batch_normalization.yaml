constraints:
  mean:
    default: null
    dtype: float16,float32,float64,uint8,complex64,complex128,int8,int16,int32,int64,bool
    init: false
    required: true
  name:
    default: null
    dtype: str
    init: false
    required: false
  offset:
    default: null
    dtype: float16,float32,float64,uint8,complex64,complex128,int8,int16,int32,int64,bool
    init: false
    required: false
  scale:
    default: null
    dtype: float16,float32,float64,uint8,complex64,complex128,int8,int16,int32,int64,bool
    init: false
    required: false
  variance:
    default: null
    dtype: float16,float32,float64,uint8,complex64,complex128,int8,int16,int32,int64,bool
    init: false
    required: true
  variance_epsilon:
    default: 0.001
    dtype: float
    init: false
    required: false
  x:
    default: null
    dtype: float16,float32,float64,uint8,complex64,complex128,int8,int16,int32,int64,bool
    init: false
    required: true
package: tf
pass_rate: 0.02
rules:
- cot: The error is triggered due to incompatible shapes during multiplication operation.
    Let's analyze the arguments. There are two tensors being multiplied in this operation.
    One possibility could be 'x' and 'scale', but they are not broadcastable since
    their dimensions are [4] and [1] respectively. Another possibility could be 'mean'
    and 'variance', but they too have different shapes [8,1,8,9,4,4,1,4] and [2,7]
    which are not broadcastable. Similarly, 'offset' and 'scale' also have different
    dimensions [2] and [1] which are not broadcastable. Therefore, the constraints
    would be that the dimensions of the tensors being multiplied should either be
    the same or one of them should be 1 to make them broadcastable.
  target: 'rror: required broadcastable shapes [Op:Mul] name:'
  txt: ((offset.dim == scale.dim) or (scale.dim == 1)) and ((x.dim == scale.dim) or
    (scale.dim == 1))
- cot: 'The error arises because the function is trying to perform a multiplication
    operation on a float tensor and an int32 tensor. However, both tensors involved
    in the operation must have the same data type. Looking at the given values for
    ''x'', ''mean'', ''variance'', ''offset'', ''scale'' and ''variance_epsilon'',
    we can see that ''x'', ''mean'', ''variance'', and ''offset'' are float32 tensors,
    while ''scale'' is an int32 tensor. Therefore, the data type of ''scale'' should
    be corrected to float32. So, Left : scale.dtype, which is the data type of tensor
    scale, should be corrected. It says that it should be equal to the datatype of
    tensor x, so Op : ==, and Right : x.dtype.'
  target: 'rror: cannot compute Mul as input #1(zero-based) was expected to be a float
    tensor but is a int32 tensor [Op:Mul] name:'
  txt: scale.dtype==x.dtype
- cot: 'The error is due to the fact that one or more of the input tensors for the
    op have a rank greater than 5. Let''s look at the given values. The tensors ''mean''
    and ''offset'' have a rank greater than 5. Therefore, we need to ensure these
    tensors do not have a rank greater than 5. So, Left : len(mean.shape) which is
    the rank of tensor ''mean'' should be corrected. It says that it should be less
    than or equal to 5, so Op : <=, and Right : 5. Similarly, for tensor ''offset'',
    Left : len(offset.shape), Op : <=, Right : 5.'
  target: 'rror: Input for dynamic binary or n-ary op lowering was of a rank greater
    than 5 [Op:AddV2] name:'
  txt: len(mean.shape)<=5
title: tf.nn.batch_normalization
