args:
  dtype:
  - Tensor
  - Tensor
  - Tensor
  - number
  is_pos:
  - true
  - false
  - false
  - false
  name:
  - self
  - tensor1
  - tensor2
  - value
  required:
  - true
  - true
  - true
  - false
name: torch.Tensor.addcmul_
package: torch
pass_rate: 100
rules:
- - cot: ''
    length: 1
    target:
      choosen_dtype:
        self: tensor
        tensor1: tensor
        tensor2: tensor
        value: int
      msg: result type Float can't be cast to the desired output type Int
      package: torch
    txt: dtype(tensor1)==dtype(tensor2) and dtype(tensor2)==dtype(self)
  - f1_score: 68.11989100817439
    overall_score: 46.059945504087196
    precision: 100.0
    recall: 51.65289256198348
- - cot: synthesized
    length: 2
    target:
      choosen_dtype:
        self: tensor
        tensor1: tensor
        tensor2: tensor
        value: int
      msg: The size of tensor a (9) must match the size of tensor b (4) at non-singleton
        dimension 6
      package: torch
    txt: (self.shape() == tensor1.shape()) or (all(self.shape[i] == tensor1.shape[i]
      or self.shape[i] == 1 or tensor1.shape[i] == 1 for i in range(-1, -min(len(self.shape),
      len(tensor1.shape))-1, -1)))
  - f1_score: 80.0936768149883
    overall_score: 46.04683840749415
    precision: 68.4
    recall: 96.61016949152543
- - cot: synthesized
    length: 3
    target:
      choosen_dtype:
        self: tensor
        tensor1: tensor
        tensor2: tensor
        value: int
      msg: output with shape [1] doesn't match the broadcast shape [1, 6, 6, 6]
      package: torch
    txt: ((self.shape == tensor2.shape) and (self.shape == tensor1.shape)) and (len(tensor1.shape)
      == len(tensor2.shape) == len(self.shape))
  - f1_score: 67.07234617985125
    overall_score: 45.536173089925626
    precision: 99.2
    recall: 50.663942798774265
