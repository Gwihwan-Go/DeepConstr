args:
  dtype:
  - Tensor
  - number
  - Tensor
  is_pos:
  - true
  - false
  - false
  name:
  - self
  - other
  - out
  required:
  - true
  - true
  - true
name: torch.bitwise_and
package: torch
pass_rate: 100
rules:
- - cot: 'Based on the given runtime information, the error occurs because the function
      `torch.bitwise_and` does not support the ''Float'' data type. The `self` tensor
      has a data type of ''Float'' (Tensor<f32>) which is not compatible with the
      operation.


      To prevent the error, the `self` tensor should have a data type that is supported
      by the `torch.bitwise_and` function. The supported data types are ''half'',
      ''int16'', ''int32'', ''int64'', ''uint8'', ''uint16'', ''uint32'', ''uint64''.


      Therefore, the constraint to prevent the error is:'
    length: 1
    target:
      choosen_dtype:
        other: int
        out: tensor
        self: tensor
      msg: '"bitwise_and_cpu" not implemented for ''Float'''
      package: torch
    txt: dtype(self) in ["half", "int16", "int32", "int64", "uint8", "uint16", "uint32",
      "uint64"]
  - f1_score: 89.15304606240713
    overall_score: 100
    precision: 100.0
    recall: 80.42895442359249
- - cot: 'The error is triggered because we are trying to resize the ''out'' tensor,
      which is of type Tensor<f32>[2, 5, 3, 3, 4, 6, 3], but it is not resizable.
      To prevent this error, the shape of the ''out'' tensor should match the shape
      of the operation results, which is the shape of the ''self'' tensor, which is
      of type Tensor<i64>[3, 7, 8, 8, 9, 8, 8].


      Therefore, the condition to prevent this error is:'
    length: 1
    target:
      choosen_dtype:
        other: int
        out: tensor
        self: tensor
      msg: Trying to resize storage that is not resizable
      package: torch
    txt: out.rank == self.rank and all(out.shape[i] == self.shape[i] for i in range(out.rank))
  - f1_score: 73.61963190184049
    overall_score: 100
    precision: 100.0
    recall: 58.252427184466015
- - cot: divided
    length: 1
    target:
      choosen_dtype:
        other: int
        out: tensor
        self: tensor
      msg: '"bitwise_and_cpu" not implemented for ''Half'''
      package: torch
    txt: dtype(self) in ["int8", "int16", "int32", "int64", "uint8", "uint16", "uint32",
      "uint64"]
  - f1_score: 99.33774834437087
    overall_score: 100
    precision: 100.0
    recall: 98.68421052631578
