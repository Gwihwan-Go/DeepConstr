topset: null # All instances will be a subset of `topset`;
# >> Example:
# topset:
#   core.MaxPool2d:
#     in_dtypes: [["f32"], ["f64"]]
#     out_dtypes: [["f32"], ["f64"]]
#   core.Where:
#     in_dtypes: [["bool", "f32", "f32"]]
#     out_dtypes: [["f32"]]

exclude: null
# >> Example:
# exclude:
#   - core.MaxPool2d:
#     in_dtypes: [["f32"], ["f64"]]
#     out_dtypes: [["f32"], ["f64"]]
#   - core.Where:
#     in_dtypes: [["bool", "f32", "f32"]]
#     out_dtypes: [["f32"]]

topset_from_file: null # Path that contains a YAML file that contains a topset domain as above

# model gen config
model:
  type: null
  path: "???" # can be multiple files tho.
  skip_err: true # skip bad models in model_exec

mgen: # model gen.
  max_nodes: 5
  pass_rate: 0.8 # 0 ~ 1 
  timeout_ms: 100000 #10000
  vulops: False
  method: "constrinf"
  save: "neuri_output"
  seed: null
  max_elem_per_tensor: 65536 # 2^16
  record_path: null # path to load records for ConcolicGenWithRecords
  test_pool: []
  noise: 0.15 # 0 ~ 1
  allow_zero_length_rate: 0.1 # 0 ~ 1
  allow_zero_rate: 0.1 # 0 ~ 1
  num_of_try: 10 ## num_of_try * noise will be the number of trials for each input
# backend config
backend:
  type: null
  optmax: true
  target: "cpu"

cache:
  topset: true # Run dtype test with automatically maintained cache

debug:
  viz: true
  viz_fmt: "png" # or "svg" for much smaller figure size and precision;
  gir_path: null

fuzz:
  time: 14400
  root: "???"
  seed: null
  crash_safe: false
  test_timeout: null
  save_test: true
  resume: false

train:
  root: "???"
  n_try: 10
  seed: null
  record_path: null
  crash_safe: false
  test_timeout: null
  resume: false
  parallel: 1
  noise: 0.15 # 0 ~ 1
  allow_zero_length_rate: 0.1 # 0 ~ 1
  allow_zero_rate: 0.1 # 0 ~ 1
  num_of_try: 10 ## num_of_try * noise will be the number of trials for each input generation
  infer_asset_per_epoch: 10
  tolerance: 3
  top_k: 10
  max_num_of_seeds: 50
  simple_eval_asset: 10 # recommend to be parallel of executor
  eval_asset: 2
  n_infer_per_round: 10

llm:
  settings:
    model_name: "gpt-3.5-turbo" # "gpt-4" # "gpt-3.5-turbo" # "gpt-3.5" # "gpt-3" # "gpt-2" # "gpt-2-xl"
    temperature: 0.7
    timeout: 7
    top_p: 1
    stop: null
    presence_penalty: 0
    frequency_penalty: 0

filter:
  type: []
  patch: []

exp: #for experiments, only using by
  api_list: null
  parallel: 1

cmp:
  equal_nan: true # skip regarding it as a bug if with fp exception values.

  raw_input: null # path to raw input data (Dict[str, np.ndarray])

  oracle: "auto"
  # "auto": use `oracle.pkl` in local path;
  # PathLike: get the oracle from somewhere else;
  # null: fallback to random.

  with:
    type: null
    optmax: true
    target: "cpu"

  seed: null
  bug_presence: "report" # or "crash"
  save: null # path to save the bug report if `bug_presence` is "report"

test:
  task:
    type: 5
  paths:
    rule: 'tests/test_rules.txt'
  package: 'tf'
  func: 'tf/raw_ops/QuantizeAndDequantizeV4'
  model_type: 'tensorflow' 
  backend_type: 'xla'
defaults:
  - override hydra/job_logging: file
  - override hydra/hydra_logging: colorlog
